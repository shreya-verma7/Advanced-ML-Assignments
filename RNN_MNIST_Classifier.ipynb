{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " RNN-MNIST-Classifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFuAFLWJOuYp"
      },
      "source": [
        "import numpy as np                   # advanced math library\n",
        "import matplotlib.pyplot as plt      # MATLAB like plotting routines\n",
        "import random  \n",
        "import tensorflow as tf\n",
        "\n",
        "                      # for generating random numbers\n",
        "from tensorflow import keras\n",
        "from keras.datasets import mnist     # MNIST dataset is included in Keras\n",
        "from keras.models import Sequential  # Model type to be used\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from keras.layers.core import Dense, Dropout, Activation # Types of layers to be used in our model\n",
        "from keras.layers import LSTM\n",
        "from keras.utils import np_utils                         # NumPy related tools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98DD1PKtazJB"
      },
      "source": [
        "**Vanishing Gradient Issue** During neural network training with backpropagation, the (local) minimum of the error function is found by iteratively taking small steps in the direction of the negative error derivative with respect to networks weights (i.e. gradients). With each subsequent layer the magnitude of the gradients gets exponentially smaller (vanishes) thus making the steps also very small which results in very slow learning of the weights in the lower layers of a deep network. It is useful for RNN in terms of processing information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yf0V8rDOa2qD"
      },
      "source": [
        "**Importance of Gates** GRU and LSTM have the cell state.The gates regulate the flow of information to the cell state. These gates can learn which data in a sequence is important and which is not. By doing that, they pass information in long sequences.The issue of short term memeory during learning process is addressed using LSTM and GRU.\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFAaIooZa7Y3"
      },
      "source": [
        "**Difference between LSTM and GRU** The key difference between GRU and LSTM is that GRU  has two gates that are reset and update while LSTM has three gates that are input, output, forget. GRU is less complex than LSTM because it has less number of gates."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4V_dPmecqh1"
      },
      "source": [
        "LSTM 32 Units"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pe5pUkhqNMIV"
      },
      "source": [
        "# Binarize the images\n",
        "def binarize(images, threshold=0.1):\n",
        "  return (threshold < images).astype('float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9iiQoh4O7bN"
      },
      "source": [
        "Loading Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7u54sxvPGLw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c88b25a-5148-4caf-97b2-cc8d8fb924b9"
      },
      "source": [
        "(X_train , y_train) , (X_test , y_test) = mnist.load_data()\n",
        "\n",
        "print(\"X_train shape\", X_train.shape)\n",
        "print(\"y_train shape\", y_train.shape)\n",
        "print(\"X_test shape\", X_test.shape)\n",
        "print(\"y_test shape\", y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train shape (60000, 28, 28)\n",
            "y_train shape (60000,)\n",
            "X_test shape (10000, 28, 28)\n",
            "y_test shape (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7k7W-u462Klr"
      },
      "source": [
        "X_train= X_train.astype(\"float32\")/255.0\n",
        "X_test = X_test.astype(\"float32\")/255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyfMfWaC41z8"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(layers.LSTM(32,input_shape=(X_train.shape[1:]),activation='relu',return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(10,activation='softmax'))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3T5uPgsszRS",
        "outputId": "002ee47a-91dd-4178-e1d1-38eb97c6837d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_22 (LSTM)               (None, 32)                7808      \n",
            "_________________________________________________________________\n",
            "dropout_45 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dropout_46 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 10,570\n",
            "Trainable params: 10,570\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pot4X6FywyfR"
      },
      "source": [
        "opt = keras.optimizers.Adam(learning_rate=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqJmTgGMtQnR"
      },
      "source": [
        "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'], loss_weights=None, weighted_metrics=None, run_eagerly=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuBcuGNAtrJE",
        "outputId": "50714d67-064f-4515-d437-5901da310aff"
      },
      "source": [
        "model.fit(X_train,y_train,epochs=10,batch_size=256,verbose=1)\n",
        "model.evaluate(X_test,y_test,batch_size=256,verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "235/235 [==============================] - 8s 28ms/step - loss: 1.9168 - accuracy: 0.3126\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 6s 27ms/step - loss: 0.6515 - accuracy: 0.7799\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 6s 27ms/step - loss: 0.4207 - accuracy: 0.8702\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 6s 27ms/step - loss: 0.3346 - accuracy: 0.8989\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 6s 27ms/step - loss: 0.2756 - accuracy: 0.9181\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 6s 27ms/step - loss: 0.2486 - accuracy: 0.9272\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 6s 28ms/step - loss: 0.2180 - accuracy: 0.9355\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 6s 27ms/step - loss: 0.1880 - accuracy: 0.9458\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 6s 27ms/step - loss: 0.1759 - accuracy: 0.9489\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 6s 27ms/step - loss: 0.1626 - accuracy: 0.9527\n",
            "40/40 - 1s - loss: 0.1203 - accuracy: 0.9637\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1202707514166832, 0.963699996471405]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GMysikXcv_2"
      },
      "source": [
        "LSTM 64 Units"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kg6nBJMfczYc",
        "outputId": "840425c2-2e55-478b-fdf7-bf9bc4f2a889"
      },
      "source": [
        "import numpy as np                   # advanced math library\n",
        "import matplotlib.pyplot as plt      # MATLAB like plotting routines\n",
        "import random  \n",
        "import tensorflow as tf\n",
        "\n",
        "                      # for generating random numbers\n",
        "from tensorflow import keras\n",
        "from keras.datasets import mnist     # MNIST dataset is included in Keras\n",
        "from keras.models import Sequential  # Model type to be used\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from keras.layers.core import Dense, Dropout, Activation # Types of layers to be used in our model\n",
        "from keras.layers import LSTM\n",
        "from keras.utils import np_utils                         # NumPy related tools\n",
        "# Binarize the images\n",
        "def binarize(images, threshold=0.1):\n",
        "  return (threshold < images).astype('float32')\n",
        "\n",
        "(X_train , y_train) , (X_test , y_test) = mnist.load_data()\n",
        "\n",
        "X_train= X_train.astype(\"float32\")/255.0\n",
        "X_test = X_test.astype(\"float32\")/255.0\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(layers.LSTM(64,input_shape=(X_train.shape[1:]),activation='relu',return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(10,activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'], loss_weights=None, weighted_metrics=None, run_eagerly=None)\n",
        "\n",
        "model.fit(X_train,y_train,epochs=10,batch_size=256,verbose=1)\n",
        "model.evaluate(X_test,y_test,batch_size=256,verbose=2)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_23 (LSTM)               (None, 64)                23808     \n",
            "_________________________________________________________________\n",
            "dropout_47 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dropout_48 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 28,618\n",
            "Trainable params: 28,618\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "235/235 [==============================] - 17s 65ms/step - loss: 1.7354 - accuracy: 0.3753\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 15s 66ms/step - loss: 0.4680 - accuracy: 0.8507\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 16s 66ms/step - loss: 0.2446 - accuracy: 0.9259\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 15s 65ms/step - loss: 0.2028 - accuracy: 0.9397\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 15s 65ms/step - loss: 0.1657 - accuracy: 0.9514\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 15s 65ms/step - loss: 0.1352 - accuracy: 0.9594\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 15s 66ms/step - loss: 0.1216 - accuracy: 0.9649\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 16s 67ms/step - loss: 0.1006 - accuracy: 0.9716\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 16s 66ms/step - loss: 0.1004 - accuracy: 0.9706\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 15s 65ms/step - loss: 0.0920 - accuracy: 0.9730\n",
            "40/40 - 1s - loss: 0.0692 - accuracy: 0.9798\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.06920892000198364, 0.9797999858856201]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1pQRjEpdzPW"
      },
      "source": [
        "GRU 32 Units"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEpCuz9Xd4xa",
        "outputId": "36233f79-06a9-429f-ccf2-a6f1cd1fb90f"
      },
      "source": [
        "import numpy as np                   # advanced math library\n",
        "import matplotlib.pyplot as plt      # MATLAB like plotting routines\n",
        "import random  \n",
        "import tensorflow as tf\n",
        "\n",
        "                      # for generating random numbers\n",
        "from tensorflow import keras\n",
        "from keras.datasets import mnist     # MNIST dataset is included in Keras\n",
        "from keras.models import Sequential  # Model type to be used\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from keras.layers.core import Dense, Dropout, Activation # Types of layers to be used in our model\n",
        "from keras.layers import LSTM\n",
        "from keras.utils import np_utils                         # NumPy related tools\n",
        "# Binarize the images\n",
        "def binarize(images, threshold=0.1):\n",
        "  return (threshold < images).astype('float32')\n",
        "\n",
        "(X_train , y_train) , (X_test , y_test) = mnist.load_data()\n",
        "\n",
        "X_train= X_train.astype(\"float32\")/255.0\n",
        "X_test = X_test.astype(\"float32\")/255.0\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(layers.GRU(32,activation='relu',input_shape=(X_train.shape[1:]),return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(10,activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'], loss_weights=None, weighted_metrics=None, run_eagerly=None)\n",
        "\n",
        "model.fit(X_train,y_train,epochs=10,batch_size=256,verbose=1)\n",
        "model.evaluate(X_test,y_test,batch_size=256,verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_6 (GRU)                  (None, 32)                5952      \n",
            "_________________________________________________________________\n",
            "dropout_49 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dropout_50 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 8,714\n",
            "Trainable params: 8,714\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "235/235 [==============================] - 7s 25ms/step - loss: 1.9961 - accuracy: 0.2525\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.8742 - accuracy: 0.6888\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.6103 - accuracy: 0.7915\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.4604 - accuracy: 0.8497\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.3659 - accuracy: 0.8879\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.3090 - accuracy: 0.9088\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.2727 - accuracy: 0.9205\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.2423 - accuracy: 0.9316\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 6s 25ms/step - loss: 0.2287 - accuracy: 0.9356\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 6s 24ms/step - loss: 0.1994 - accuracy: 0.9437\n",
            "40/40 - 1s - loss: 0.1359 - accuracy: 0.9603\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1359158158302307, 0.9603000283241272]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yS8i3j9SeMnN"
      },
      "source": [
        "GRU 64 Units"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJ6s6-YQeOvl",
        "outputId": "3772fb7a-e447-4cf7-8e23-4d041791e75b"
      },
      "source": [
        "import numpy as np                   # advanced math library\n",
        "import matplotlib.pyplot as plt      # MATLAB like plotting routines\n",
        "import random  \n",
        "import tensorflow as tf\n",
        "\n",
        "                      # for generating random numbers\n",
        "from tensorflow import keras\n",
        "from keras.datasets import mnist     # MNIST dataset is included in Keras\n",
        "from keras.models import Sequential  # Model type to be used\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from keras.layers.core import Dense, Dropout, Activation # Types of layers to be used in our model\n",
        "from keras.layers import LSTM\n",
        "from keras.utils import np_utils                         # NumPy related tools\n",
        "# Binarize the images\n",
        "def binarize(images, threshold=0.1):\n",
        "  return (threshold < images).astype('float32')\n",
        "\n",
        "(X_train , y_train) , (X_test , y_test) = mnist.load_data()\n",
        "\n",
        "X_train= X_train.astype(\"float32\")/255.0\n",
        "X_test = X_test.astype(\"float32\")/255.0\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(layers.GRU(64,activation='relu',input_shape=(X_train.shape[1:]),return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(10,activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'], loss_weights=None, weighted_metrics=None, run_eagerly=None)\n",
        "\n",
        "model.fit(X_train,y_train,epochs=10,batch_size=256,verbose=1)\n",
        "model.evaluate(X_test,y_test,batch_size=256,verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_7 (GRU)                  (None, 64)                18048     \n",
            "_________________________________________________________________\n",
            "dropout_51 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dropout_52 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_45 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 22,858\n",
            "Trainable params: 22,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "235/235 [==============================] - 15s 55ms/step - loss: 1.8067 - accuracy: 0.3273\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 13s 55ms/step - loss: 0.5328 - accuracy: 0.8187\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 13s 54ms/step - loss: 0.3259 - accuracy: 0.9020\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 13s 55ms/step - loss: 0.2443 - accuracy: 0.9281\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 13s 55ms/step - loss: 0.1976 - accuracy: 0.9439\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 13s 55ms/step - loss: 0.1809 - accuracy: 0.9470\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 13s 54ms/step - loss: 0.1435 - accuracy: 0.9590\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 13s 55ms/step - loss: 0.1291 - accuracy: 0.9622\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 13s 55ms/step - loss: 0.1161 - accuracy: 0.9667\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 13s 56ms/step - loss: 0.1057 - accuracy: 0.9692\n",
            "40/40 - 1s - loss: 0.0807 - accuracy: 0.9755\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0807291567325592, 0.9754999876022339]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwadZrCMerEF"
      },
      "source": [
        "Stacked LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        },
        "id": "xLCf2cLQetqg",
        "outputId": "66163e5a-ff3b-47bd-db0a-7d366f2e183b"
      },
      "source": [
        "import numpy as np                   # advanced math library\n",
        "import matplotlib.pyplot as plt      # MATLAB like plotting routines\n",
        "import random  \n",
        "import tensorflow as tf\n",
        "\n",
        "                      # for generating random numbers\n",
        "from tensorflow import keras\n",
        "from keras.datasets import mnist     # MNIST dataset is included in Keras\n",
        "from keras.models import Sequential  # Model type to be used\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from keras.layers.core import Dense, Dropout, Activation # Types of layers to be used in our model\n",
        "from keras.layers import LSTM\n",
        "from keras.utils import np_utils                         # NumPy related tools\n",
        "# Binarize the images\n",
        "def binarize(images, threshold=0.1):\n",
        "  return (threshold < images).astype('float32')\n",
        "\n",
        "(X_train , y_train) , (X_test , y_test) = mnist.load_data()\n",
        "\n",
        "X_train= X_train.astype(\"float32\")/255.0\n",
        "X_test = X_test.astype(\"float32\")/255.0\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(layers.LSTM(32,input_shape=(X_train.shape[1:]),activation='relu',return_sequences=True)) \n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(layers.LSTM(32,activation='relu',return_sequences=True)) \n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(layers.LSTM(32,activation='relu',return_sequences=True)) \n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(layers.LSTM(32,activation='relu',return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(10,activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'], loss_weights=None, weighted_metrics=None, run_eagerly=None)\n",
        "\n",
        "model.fit(X_train,y_train,epochs=10,batch_size=256,verbose=1)\n",
        "model.evaluate(X_test,y_test,batch_size=256,verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_28\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_30 (LSTM)               (None, 28, 32)            7808      \n",
            "_________________________________________________________________\n",
            "dropout_64 (Dropout)         (None, 28, 32)            0         \n",
            "_________________________________________________________________\n",
            "lstm_31 (LSTM)               (None, 28, 32)            8320      \n",
            "_________________________________________________________________\n",
            "dropout_65 (Dropout)         (None, 28, 32)            0         \n",
            "_________________________________________________________________\n",
            "lstm_32 (LSTM)               (None, 28, 32)            8320      \n",
            "_________________________________________________________________\n",
            "dropout_66 (Dropout)         (None, 28, 32)            0         \n",
            "_________________________________________________________________\n",
            "lstm_33 (LSTM)               (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dropout_67 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_52 (Dense)             (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dropout_68 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_53 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 35,530\n",
            "Trainable params: 35,530\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            " 57/235 [======>.......................] - ETA: 21s - loss: 2.2641 - accuracy: 0.1522"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-87708ab573c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweighted_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_eagerly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BO1MAz3SeuOi"
      },
      "source": [
        "Stacked GRU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uY2otv7_ew3-",
        "outputId": "aa02e3ac-b1d2-463e-837e-8f3f97d0959f"
      },
      "source": [
        "import numpy as np                   # advanced math library\n",
        "import matplotlib.pyplot as plt      # MATLAB like plotting routines\n",
        "import random  \n",
        "import tensorflow as tf\n",
        "\n",
        "                      # for generating random numbers\n",
        "from tensorflow import keras\n",
        "from keras.datasets import mnist     # MNIST dataset is included in Keras\n",
        "from keras.models import Sequential  # Model type to be used\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from keras.layers.core import Dense, Dropout, Activation # Types of layers to be used in our model\n",
        "from keras.layers import LSTM\n",
        "from keras.utils import np_utils                         # NumPy related tools\n",
        "# Binarize the images\n",
        "def binarize(images, threshold=0.1):\n",
        "  return (threshold < images).astype('float32')\n",
        "\n",
        "(X_train , y_train) , (X_test , y_test) = mnist.load_data()\n",
        "\n",
        "X_train= X_train.astype(\"float32\")/255.0\n",
        "X_test = X_test.astype(\"float32\")/255.0\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(layers.GRU(32,input_shape=(X_train.shape[1:]),activation='relu',return_sequences=True)) \n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "model.add(layers.GRU(32,activation='relu',return_sequences=True)) \n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "model.add(layers.GRU(32,activation='relu',return_sequences=True)) \n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "model.add(layers.GRU(32,activation='relu',return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Dense(10,activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'], loss_weights=None, weighted_metrics=None, run_eagerly=None)\n",
        "\n",
        "model.fit(X_train,y_train,epochs=10,batch_size=256,verbose=1)\n",
        "model.evaluate(X_test,y_test,batch_size=256,verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "gru_8 (GRU)                  (None, 28, 32)            5952      \n",
            "_________________________________________________________________\n",
            "dropout_56 (Dropout)         (None, 28, 32)            0         \n",
            "_________________________________________________________________\n",
            "gru_9 (GRU)                  (None, 32)                6336      \n",
            "_________________________________________________________________\n",
            "dropout_57 (Dropout)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_48 (Dense)             (None, 64)                2112      \n",
            "_________________________________________________________________\n",
            "dropout_58 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_49 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 15,050\n",
            "Trainable params: 15,050\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "235/235 [==============================] - 15s 53ms/step - loss: 1.8811 - accuracy: 0.2777\n",
            "Epoch 2/10\n",
            "235/235 [==============================] - 13s 53ms/step - loss: 0.7927 - accuracy: 0.7144\n",
            "Epoch 3/10\n",
            "235/235 [==============================] - 13s 53ms/step - loss: 0.5199 - accuracy: 0.8218\n",
            "Epoch 4/10\n",
            "235/235 [==============================] - 13s 53ms/step - loss: 0.3451 - accuracy: 0.8958\n",
            "Epoch 5/10\n",
            "235/235 [==============================] - 12s 53ms/step - loss: 0.2568 - accuracy: 0.9258\n",
            "Epoch 6/10\n",
            "235/235 [==============================] - 13s 54ms/step - loss: 0.2278 - accuracy: 0.9357\n",
            "Epoch 7/10\n",
            "235/235 [==============================] - 12s 53ms/step - loss: 0.2005 - accuracy: 0.9442\n",
            "Epoch 8/10\n",
            "235/235 [==============================] - 13s 54ms/step - loss: 0.1741 - accuracy: 0.9505\n",
            "Epoch 9/10\n",
            "235/235 [==============================] - 13s 54ms/step - loss: 0.1540 - accuracy: 0.9578\n",
            "Epoch 10/10\n",
            "235/235 [==============================] - 13s 54ms/step - loss: 0.1478 - accuracy: 0.9596\n",
            "40/40 - 1s - loss: 0.0901 - accuracy: 0.9736\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.09008524566888809, 0.9735999703407288]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gz-xyQ5beNmX"
      },
      "source": [
        "The accuracy is fairly high, which gives me a sense that there is a scope of overfitting. \n",
        "The computational time of GRU was fairly less."
      ]
    }
  ]
}